\chapter{Numerical Techniques}
A number of numerical techniques can be used to solve heat transfer in stockpiles. Initially we will use finite differences. This method is useful for simple domains, but for more complex geometries, it becomes more challenging to implement. The finite element method is another technique that can be used. One of the key benefits about this method is that the generalisation to complex domains is simple. There are numerous software packages developed for finite elements including; FlexPDE, and Matlab's PDE Toolbox. 
The following theory for finite difference methods has been sourced from \cite{strik}.\\
For many differential equations, solutions cannot be found analytically. As a result, numerical schemes are required. It is useful to obtain an estimate of how accurate the numerical solution is. To make the analysis easier it is useful to introduce some notation.\\
Let $P$ be a differential operator such that,
\begin{equation}
Pu=0,\label{Diff_op}
\end{equation} 
where $u:(0,\infty)\times\Omega\subset\R^n\rightarrow \R$.\\
Initially we consider $P$ to be a linear differential operator.
\section{The Finite Difference Operator}
\label{fin_diff}
To introduce the finite difference operator we need to consider the space of functions that it operates on. To think about this we first consider the domain $\Omega=\R$. The standard discretisation of this domain is into a grid of equally spaced nodes with spacing $h$. This can be denoted by,
\begin{equation*}
h\Z=\{hz:z\in \Z\}.
\end{equation*}
A similar discretisation is required for the time component as well. We define,
\begin{equation*}
k\N_0=\{kn:n\in \N\cup\{0\}\},
\end{equation*}
where $k$ is the spacing of each nodes.
For practicality we consider $k,h>0$.\\
Consider a function $v: k\N_0 \times h\Z \rightarrow \R$ and let $v^n_m$ denote the value of the function at the point $\left( n,m \right)\in k\N_0 \times h\Z$.
We seek a difference operator, $P_{h,k}$ such that solutions to the equation,
\begin{equation}
P_{k,h}v=0, \label{fin_op}
\end{equation} 
can be used to approximate the solutions to equation \ref{Diff_op}. A common example of a finite difference operator is the forward difference operator, $\delta_+$, given by, $$\delta_+ v_m=\frac{v_{m+1}-v_m}{h}.$$
This is often denoted as $\delta_{x+}$ as it is with respect to the $x$ variable. Similarly we can define $\delta_t+$ as, 
$$\delta_{t+}v^n=\frac{v^{n+1}-v^n}{k}.$$
We also have a backward and central difference operators $\delta_-$ and $\delta_0$, defined by,
$$\delta_-v_m=\frac{v_m-v_{m-1}}{h},$$
$$\delta_0 v_m=\frac{v_{m+1}-v_{m-1}}{2h}.$$
In each of these cases $h,k$ represents the grid spacing of the function $v_m^n$. The central difference can also be generated by the average of the forward and backward differences.\\
These differences are used to approximate first derivatives. We can find a similar finite difference for higher order derivatives. The central difference operator for the second derivative is $\delta_+\delta_-$ which is denoted by $\delta^2$ .
\section{Convergence}
It would be good to use this difference operator to produce approximate solutions, though we have not set a definition for convergence.
\begin{definition}
A finite difference scheme approximating a differential operator is convergent, if for a solution $u(t,x)$ of equation \ref{Diff_op} and the solution, $v_m^n$, to equation \ref{fin_op} such that $v_m^0$ converges to $u(0,x)$ as $mh$ approaches $x$, then $v_m^n$ converges to $u(t,x)$ as $(nk,mh)$ converges to $(t,x)$ as $h,k \rightarrow 0$.
\end{definition} 
This definition does not provide a norm for the convergence and the functions, $u(t_n,x)$ and $v_m^n$ are in different spaces so it is not clear as to how to define convergence.\\
For finite difference schemes it is useful to to consider consistency. Consistency is the idea that the differential operator is well approximated by the difference operator.
\begin{definition}
A finite difference operator $P_{k,h}$ is consistent with a differential operator $P$ if for any smooth function $\phi$, $\lvert\lvert P_{k,h}\phi-P\phi\rvert\rvert \rightarrow 0$ as $h,k\rightarrow 0$,
where the convergence is point-wise at each grid point.
\end{definition} 
\begin{exmp}
We consider the example where $P=\frac{\partial}{\partial t}-\frac{\partial^2}{\partial x^2}-F$, and $F$ is a function of the argument. The finite difference operator $P_{k,h}=\delta_{t+}-\delta_x^2-F$. We wish to show consistency of these operators.\\
To determine consistency we need only to show that the finite difference approximations are consistent with the respective differential forms since, 
\begin{equation}
\lvert P\phi-P_{k,h}\phi\rvert\leq \bigg\lvert \frac{\partial\phi}{\partial t}-\delta_{t+}\phi\bigg\rvert+\bigg\lvert \frac{\partial^2\phi}{\partial x^2} -\delta_x^2 \phi\bigg\rvert. 
\end{equation}
The functional terms $F(\phi)$ drop out of the equation since the difference operator just evaluates the function at that point. \\
For the forward difference, since $\phi$ is smooth,
\begin{align*}
\delta_{t+}\phi(t_n,x_m)&=\frac{\phi(t_n+k,x_m)-\phi(t_n,x_m)}{k}.\\
\end{align*}
For simplicity we drop the $x_m$ variable as this is just an equation for each $x_m$. We expand $\phi(t_n+k)$ by it's Taylor series about $t_n$,
$$\phi(t_n+k)=\phi(t_n)+k\frac{d\phi}{dt}\bigg\rvert_{t=t_n}+\mathcal{O}(k^2)$$
Rearranging this equation, we get,
\begin{equation}
\frac{\phi(t_n+k)-\phi(t_n)}{k}=\frac{d\phi}{dt}\bigg\rvert_{t=t_n}+\mathcal{O}(k). 
\end{equation}
Similarly we can show for the central difference that,
\begin{equation}
\delta_x^2\phi-\frac{\partial^2\phi}{\partial x^2}=\mathcal{O}(h^2). \label{accuracy}
\end{equation} 
Combining these two components, then,
\begin{equation}
\lvert P\phi-P_{k,h}\phi\rvert\leq\mathcal{O}(k)+\O(h^2). 
\end{equation}
This approaches 0 as $h,k$ approach $0$. 
\end{exmp}

With that example it is useful to introduce the notion of order of accuracy. 
\begin{definition}
A finite difference scheme $P_{k,h}v=0$ that is consistent with the differential equation $Pu=0$ is accurate of order $p$ in time and $q$ in space, if  for any smooth function $\phi$,
$$ \lvert P\phi-P_{k,h}\phi\rvert=\O(k^p)+\O(h^q). $$
\end{definition}
The next concept that needs to be defined is stability.
\begin{definition}
A linear finite difference scheme $P_{k,h}v_m^n=0$ is stable in a stability region $\Lambda$ if there exists an integer $J$ such that for any positive time $T$, there exists a constant $C_T$ such that,
\begin{equation}
\sum_{m=-\infty}^{\infty} \lvert v_m^n\rvert^2 \leq C_T \sum_{j=0}^J\sum_{m=-\infty}^{\infty}\lvert v_m^j\rvert^2,
\end{equation} 
for all $nk\leq T$ for $(h,k)\in \Lambda$.
\end{definition}
In general for single-step time schemes, the constant $J$ is taken as $0$.

\begin{theorem}[Lax-Richtmyer Equivalence Theorem]
A finite difference scheme consistent with the differential equation, for which the initial value problem is well-posed, is convergent if and only if it is stable.
\end{theorem}
The proof of this theorem requires the use of Fourier transforms and also a more appropriate sense of convergence.\\
%\section{Convergence}
To discuss the convergence of the finite difference schemes, we need to consider functions in the same space. To do this we introduce two operators. 
\begin{definition}
The truncation operator $T$ maps functions in $L^2(\R)$ to function in $L^2(h\Z)$. Given $u \in L^2(\R)$, such that,
\begin{equation}
u(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{ix\xi}\hat{u}(\xi)d\xi. 
\end{equation}   
$Tu$ is defined as,
\begin{equation}
Tu_m=\frac{1}{\sqrt{2\pi}}\int_{-\frac{\pi}{h}}^{\frac{\pi}{h}}e^{imh\xi}\hat{u}(\xi)d\xi, 
\end{equation}
for each grid point $mh\in h\Z$.\\
When we consider the discrete Fourier transform of $Tu$,
\begin{equation}
\widehat{Tu}(\xi)=\hat{u}(\xi) \qquad \lvert\xi\rvert\leq \frac{\pi}{h}
\end{equation} 
\end{definition}
\begin{definition}
The interpolation operator $S$  maps functions from $L^2(h\Z)$ to functions in $L^2(\R)$. Given $v \in L^2(h\Z)$, with 
$$ v_m= \frac{1}{\sqrt{2\pi}}\int_{\frac{-\pi}{h}}^{\frac{\pi}{h}} e^{imh\xi}\hat{v}(x)$$
then $Sv$ is defined as,
$$Sv(x)=\frac{1}{\sqrt{2\pi}}\int_{\frac{-\pi}{h}}^{\frac{\pi}{h}} e^{ix\xi}\hat{v}(x).$$
\end{definition}
These operators are also defined in terms of the grid spacing, $h$, though this is left out of the notation.
Using these two operators we can then define convergence in terms of the interpolation operator.
\begin{definition}
A finite difference scheme approximating  the homogeneous initial value problem for a partial differential equation is a convergent scheme if $Sv^n$ converges to $u(t_n,\cdot)$ in $L^2(\R)$, where $t_n=nk$, for every solution $u$ to the differential equation and every set of solutions to the difference scheme v. depending on $h$, and $k$, for which $Sv^0$ converges to $u(0,\cdot)$ in $L^2(\R)$ as $h$ and $k$ tend to $0$
\end{definition}

\section{Non-linear Convergence}
The convergence theory in the previous section related to linear problems rather than non-linear. For the problem of interest we have a non-linear problem which requires more specific techniques to deal with convergence. A simple theorem cannot provide convergence for all types of non-linear problems. In this section we look at a convergence theorem for a general parabolic function on a 1-dimensional domain with Dirichlet boundary conditions. The convergence results presented are from Reynolds \cite{reynolds72}. \\
Consider the Partial differential equation given by,
\begin{equation}
u_t=f(t,x,u,u_x,u_xx)\quad	\text{in}\quad 	[0,T]\times(a,b), \label{Par_DE}
\end{equation}
\begin{equation}
u(0,x)=\psi(x),\quad u(t,a)=\psi_0(t), \quad \textrm{and} \quad u(t,b)=\psi_1(t), \label{Par_BC}
\end{equation}
where $\psi(a)=\psi_0(0)$ and $\psi(b)=\psi_1(0)$.\\
We consider a discrete mesh over the domain $[0,T]\times (a,b)$ defined by  the set of points $(t_i,x_j)$ such that,
\begin{align*}
h&=\frac{b-a}{m+1},\\
x_j&=a+ih,\\
\Delta t&=\frac{T}{n},\\
t_i&= i\Delta t,\\
\end{align*}
for $i=1,2,...,n$ and j=$0,1,...,m+1$.\\
We can also define functions on this mesh. Let $v(t,x)$, be a functioned defined on the domain $[0,T]\times (a,b)$. Then the function defined on the mesh $v_j^i=v(t_i,x_j)$, for $i=1,2,...,n$ and j=$0,1,...,m+1$. The notation used here is to be consistent with the previous sections. \\
We use the finite differences that were defined in section \ref{fin_diff} to replace our derivatives. We shall also simplify our notation by denoting $f(t_i,x_j,v^i_j,\delta_0v^i_j,\delta^2v^i_j)$ by $f(v^i_j)$, where the differences are taken in space. For $i=1,2,...,n$ and j=$0,1,...,m+1$ let $\alpha_j(t_i)$ and $\beta_j(t_i)$ be defined by $u_x(t_i,x_j)=\delta_0(u^i_j)+\alpha_j(t_i)$ and $u_{xx}(t_i,x_j)=\delta^2 u^i_j+\beta_j(t_i)$, where we have assumed that u(t,x) is the unique solution to \ref{Par_DE}-\ref{Par_BC}. Assuming that $u$ has sufficient regularity then then $\alpha_j$ and $\beta_j$ are $\O (h^2)$.    
By replacing the derivatives in equation \ref{Par_DE}, we can consider the discrete problem given by,
\begin{equation}
\delta_{t-}v^i_j=\theta f(v^i_j)+(1-\theta)f(v^{i-1}_j) \quad \text{for	} 1\leq i\leq n \text{ and } 1\leq j\leq m, \label{par_fin}
\end{equation}
\begin{equation}
v_0^i=\psi_0(t_i), \quad v_{n+1}^i=\psi_1(t_i) \quad \textrm{and} \quad v^0_j=\psi(x_j).
\end{equation}

In order examine the convergence theorem we wish to place some restrictions on the function $f$. 
Suppose there exists such constants $\alpha,A, B \geq 0$ and constants $C$ and $C'$ such that $f$ satisfies,
\begin{equation}
\alpha\left(\bar{r}-r\right)\leq f(t,x,z,p,\bar{r})-f(t,x,z,p,r)\leq A(\bar{r}-r), \quad \bar{r}\geq r,
\label{L1}
\end{equation}
\begin{equation}
\lvert f(t,x,z,\bar{p},r)-f(t,x,z,p,r)\rvert\leq B\lvert\bar{p}-p\rvert, \label{L2}
\end{equation}
\begin{equation}
-C\left(\bar{z}-z\right)\leq f(t,x,\bar{z},p,r)-f(t,x,z,p,r)\leq C'(\bar{z}-z). \label{L3}
\end{equation}
These restrictions are similar to Lipschitz conditions, where condition Equation \ref{L2} is exactly a Lipschitz condition. The value of these conditions is that we can bound the non-linear terms in the function by linear terms.\\
There are also some restrictions that are placed on the grid size.
Suppose the grid parameters, $\Delta t$ and $h$, satisfy,
\begin{align}
\theta \Delta tC'&\leq 1, \label{G1}\\
\alpha-\frac{hB}{2}&\geq 0,\label{G2}\\
\left(1-\theta\right)2\left(A\frac{\Delta t}{h^2}\right) &\leq 1+\left( 1-\theta\right)\left(-C\right)\label{G3}.
\end{align}
 Given these restrictions then the main theorem can be stated.

\begin{theorem}
\label{conv}
Let $u$ denote the unique solution to equations \ref{Par_DE} and \ref{Par_BC}, and have bounded derivatives, $u_{tt}$ and $u_{xxxx}$. Suppose $f$ satisfies \cref{L1,L2,L3} and \cref{G1,G2,G3}.\\ 
Suppose there exists a function $\omega$ defined on $[0,T]\times \R^3$ and a function $\rho >0$, $\rho\in C^1([0,T])$, such that,
\begin{equation}
f(t,x,\bar{z},\bar{p},\bar{r})-f(t,x,z,p,r)\leq \omega(t,\bar{z}-z,\lvert \bar{p}-p\rvert,\lvert \bar{r}-r\rvert) \quad \textrm{for } \bar{z}\geq z,
\end{equation}  
\begin{equation}
\rho'(t')\geq 2\omega(\bar{t},\rho(\bar{t}),\lvert \alpha_j\rvert,\lvert \beta_j\rvert) \ on \ [0,T] \ \mathrm{for} \ i=1,2,...,n \ \mathrm{and}\ \lvert \bar{t}-t'\rvert \geq \Delta t,
\end{equation}
\begin{equation}
\rho '(t')> \Delta t \sup_{0<\bar{t}\leq T,1\leq j\leq m} \lvert u_{tt}(\bar{t},x_j)\rvert \quad \mathrm{for} \lvert \bar{t}-t\rvert \leq \Delta t.
\end{equation}
Then, $\sup_{0\leq j \leq m+1}\lvert(u(t_i,x_j)-v^i_j\rvert \leq \rho(t_i)$ for $i=0,1,...,n$, where $v^i_j$ is the solution to \ref{par_fin}

\end{theorem}

This theorem does not guarantee convergence as $\Delta t$ and $h$ approach zero. This is because no information is given on the nature of the function $\rho$. However a function for $\rho$ can be constructed that is of order $\Delta t + h^2$.
This convergence result is also limited to Dirichlet boundary conditions. 

%Whilst this theorem doesn't explicitly state that the equations converge, it provides an upper bound on the difference at each node. As a result if the solution oscillates on a much finer mesh,this detail is not necessarilly captured. What is not stated in this theorem is how the function $\rho$ behaves. It is possible to construct a function $\rho$ that is $\O(\Delta t)+\O(h^2)$ which provides convergence as $\Delta t, h$ approach $0$.\\
%The paper also provides a method of construction for the functions $\omega$ and $\rho$ such that conditions 17-22 are sufficient to provide convergence.

%\section{Finite Elements}
%Finite elements can provide a useful tool especially when looking at elliptic problems. One of the main advantageous with using finite elements is that it simplifies the method for complex domains. This is due to the triangulation that is applied to the domain rather than a grid. In order to introduce the finite element method some background around weak derivatives and Sobolev spaces need to be introduced.
%\begin{definition}
%Let $\Omega \subset \R^n$. We define the function space $L^P(\Omega)$ as the space of all functions, $f$, such that the integral, $\int_\Omega \lvert f\rvert^p$, is finite.
%\end{definition}

%\begin{definition}
%Let $u$ be a function in $L^p(\Omega)$. Then if there exists a function $w \in L^P(\Omega)$ such that,
%$$ \int_\Omega u v'=-\int_\Omega wv,$$
%for all smooth, compactly supported test functions $v$, then $w$ is the weak derivative of $v$. 
%\end{definition}
%\begin{definition}{Sobolev Space}
%We define the space $W^{k,p}$ as the space for which the kth weak derivatives are all in $L^P(\Omega)$.
%\end{definition}
% The simplist way to look at the finite element method is to use examples. A very simple example is the poisson problem on the unit interval with direchlet boundary conditions. 
%\subsection{The Poisson Problem}
%The poisson problem is as follows,
%\begin{equation}
%\vartriangle u=f.
%\end{equation}
